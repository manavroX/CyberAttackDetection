{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse Random Forest with a bootstrap method to predict which flow is a malware.\\n\\nParameters\\n----------\\ndata_window_botnetx.h5         : extracted data from preprocessing1.py\\ndata_window3_botnetx.h5        : extracted data from preprocessing2.py\\ndata_window_botnetx_labels.npy : label numpy array from preprocessing1.py\\n\\nReturn\\n----------\\nPrint train and test accuracy, precison, recall, f1 and support\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Antoine DELPLACE\n",
    "# Last update: 17/01/2020\n",
    "\"\"\"\n",
    "Use Random Forest with a bootstrap method to predict which flow is a malware.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data_window_botnetx.h5         : extracted data from preprocessing1.py\n",
    "data_window3_botnetx.h5        : extracted data from preprocessing2.py\n",
    "data_window_botnetx_labels.npy : label numpy array from preprocessing1.py\n",
    "\n",
    "Return\n",
    "----------\n",
    "Print train and test accuracy, precison, recall, f1 and support\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csc_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import h5py\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, feature_selection, kernel_approximation, ensemble, linear_model, metrics, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import data\n"
     ]
    }
   ],
   "source": [
    "print(\"Import data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_hdf('data_window_botnet3.h5', key='data')\n",
    "X.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.read_hdf('data_window3_botnet3.h5', key='data')\n",
    "X2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.join(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('window_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['Label_<lambda>']\n",
    "X.drop('Label_<lambda>', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"data_window_botnet3_labels.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['counts' 'Sport_nunique' 'DstAddr_nunique' 'Dport_nunique' 'Dur_sum'\n",
      " 'Dur_mean' 'Dur_std' 'Dur_max' 'Dur_median' 'TotBytes_sum'\n",
      " 'TotBytes_mean' 'TotBytes_std' 'TotBytes_max' 'TotBytes_median'\n",
      " 'SrcBytes_sum' 'SrcBytes_mean' 'SrcBytes_std' 'SrcBytes_max'\n",
      " 'SrcBytes_median' 'Sport_RU' 'DstAddr_RU' 'Dport_RU']\n",
      "['flow=Background' 'flow=To-Backgro' 'flow=From-Backg' 'flow=From-Norma'\n",
      " 'flow=To-Normal-' 'flow=Normal-V42' 'flow=From-Botne']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(X.columns.values)\n",
    "print(labels)\n",
    "print(np.where(labels == 'flow=From-Botne')[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin6 = y==np.where(labels == 'flow=From-Botne')[0][0]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_bin6, test_size=0.33, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491902\n",
      "734818\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_test)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"ytest.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491902, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train_new, y_train_new = utils.resample(X_train, y_train, n_samples=X_train.shape[0]*20, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_train_new)\n",
    "ynew = ynew.reshape(-1,40)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"ytrain.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (array([list([0]), list([1]), list([2]), list([3]), list([4]), list([6])],\n",
      "      dtype=object), array([2207092,   18047,     263,     984,      48,     286]))\n",
      "y_train (array([False,  True]), array([29834014,     4026]))\n",
      "y_test (array([False,  True]), array([734736,     82]))\n"
     ]
    }
   ],
   "source": [
    "print(\"y\", np.unique(y, return_counts=True))\n",
    "print(\"y_train\", np.unique(y_train_new, return_counts=True))\n",
    "print(\"y_test\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 24.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=80, random_state=123456, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=80, random_state=123456, verbose=1, class_weight=None)\n",
    "clf.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "y_pred_train = clf.predict(X_train_new)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_train)\n",
    "ynew = ynew.reshape(-1,40)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734818\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_test)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_rf_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_seed = np.random.randint(0, 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/2019a7ps1343h/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=550, class_weight={0: 0.044, 1: 0.956}, max_iter=700,\n",
       "                   random_state=828082930)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression(penalty='l2', C=550, random_state=tab_seed, multi_class=\"auto\", class_weight={0:0.044, 1:1-0.044}, solver=\"lbfgs\", max_iter=700, verbose=0)\n",
    "clf.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "y_pred_train = clf.predict(X_train_new)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_train)\n",
    "ynew = ynew.reshape(-1,40)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_lr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_test)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_lr_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, AveragePooling2D, Dense, Dropout, Flatten, Lambda, MaxPool2D, Conv2DTranspose, UpSampling2D, Concatenate, Add\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inputs, dropout=0.5, batchnorm=True):\n",
    "    x = Dense(256, input_shape=(22,))(inputs)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Dense(128, input_shape=(256,))(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Dense(1, input_shape=(128,))(x)\n",
    "    outputs = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_seed = np.random.randint(0, 1000000000)\n",
    "filename_weights = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprecision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frecall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff1_score(y_true, y_pred):\n",
    "    \"\"\"Computes the F1 Score\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\n",
    "    p = fprecision(y_true, y_pred)\n",
    "    r = frecall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inputs, dropout=0.5, batchnorm=True):\n",
    "    x = Dense(256, input_shape=(22,))(inputs)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Dense(128, input_shape=(256,))(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Dense(1, input_shape=(128,))(x)\n",
    "    outputs = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/2019a7ps1343h/.local/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00099, saving model to model.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00099 to 0.00053, saving model to model.h5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00053\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00053 to 0.00045, saving model to model.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00045\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00045\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00045 to 0.00041, saving model to model.h5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00041 to 0.00036, saving model to model.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00036\n",
      "Execution time =  1639.5491924285889\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((22,), name='input')\n",
    "model = get_model(inputs, dropout=0, batchnorm=1)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filename_weights, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-3), loss=[\"binary_crossentropy\"], metrics=[fprecision, frecall, ff1_score])\n",
    "#model.summary()\n",
    "\n",
    "tps = time.time()\n",
    "results = model.fit(X_train, y_train, batch_size=32, epochs=13, validation_split=0.15, shuffle=True, class_weight=None, verbose=0, callbacks=callbacks)\n",
    "print(\"Execution time = \", time.time()-tps)\n",
    "\n",
    "model.load_weights(filename_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train, batch_size=32, verbose=0)\n",
    "y_pred_train_bin = (y_pred_train > 0.5).astype(np.uint8)\n",
    "print(y_pred_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_train_bin)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_nn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "y_pred_test = model.predict(X_test, batch_size=32, verbose=0)\n",
    "y_pred_test_bin = (y_pred_test > 0.5).astype(np.uint8)\n",
    "print(y_pred_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_test_bin)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_nn_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_seed = np.random.randint(0, 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(loss='exponential', learning_rate=0.1, n_estimators=33, max_depth=4, random_state=tab_seed, verbose=0)\n",
    "clf.fit(X_train_new, y_train_new)\n",
    "y_pred_train = clf.predict(X_train_new)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_train)\n",
    "ynew = ynew.reshape(-1,40)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_gb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_test)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_gb_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_nystroem = kernel_approximation.Nystroem(kernel='poly', gamma=None, degree=2, n_components=200, random_state=123456)\n",
    "feature_map_nystroem.fit(X_train)\n",
    "X_train_new = feature_map_nystroem.transform(X_train)\n",
    "X_test_new = feature_map_nystroem.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 611434.98, NNZs: 200, Bias: -6873.173385, T: 1491902, Avg. loss: 36.683272\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 499270.70, NNZs: 200, Bias: -10604.367865, T: 2983804, Avg. loss: 20.351496\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 422247.09, NNZs: 200, Bias: -11536.796979, T: 4475706, Avg. loss: 10.730387\n",
      "Total training time: 2.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 366052.88, NNZs: 200, Bias: -12616.671616, T: 5967608, Avg. loss: 6.050920\n",
      "Total training time: 3.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 323215.92, NNZs: 200, Bias: -13370.153168, T: 7459510, Avg. loss: 3.559299\n",
      "Total training time: 4.58 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 289436.25, NNZs: 200, Bias: -14379.140825, T: 8951412, Avg. loss: 2.211512\n",
      "Total training time: 5.49 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 262122.66, NNZs: 200, Bias: -14646.605027, T: 10443314, Avg. loss: 1.414755\n",
      "Total training time: 6.42 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 239488.99, NNZs: 200, Bias: -14950.020574, T: 11935216, Avg. loss: 1.118370\n",
      "Total training time: 7.33 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 220448.65, NNZs: 200, Bias: -14792.688977, T: 13427118, Avg. loss: 0.935441\n",
      "Total training time: 8.25 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 204185.95, NNZs: 200, Bias: -14781.612916, T: 14919020, Avg. loss: 0.795885\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 190160.24, NNZs: 200, Bias: -14589.602810, T: 16410922, Avg. loss: 0.677679\n",
      "Total training time: 10.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 177934.07, NNZs: 200, Bias: -14281.773996, T: 17902824, Avg. loss: 0.602723\n",
      "Total training time: 11.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 167174.19, NNZs: 200, Bias: -14077.917976, T: 19394726, Avg. loss: 0.525082\n",
      "Total training time: 11.91 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157635.84, NNZs: 200, Bias: -13891.178137, T: 20886628, Avg. loss: 0.462477\n",
      "Total training time: 12.83 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 149108.76, NNZs: 200, Bias: -13859.880045, T: 22378530, Avg. loss: 0.423313\n",
      "Total training time: 13.74 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 141456.31, NNZs: 200, Bias: -13723.807226, T: 23870432, Avg. loss: 0.386937\n",
      "Total training time: 14.65 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 134548.39, NNZs: 200, Bias: -13593.177248, T: 25362334, Avg. loss: 0.349712\n",
      "Total training time: 15.56 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 128274.94, NNZs: 200, Bias: -13502.784282, T: 26854236, Avg. loss: 0.325909\n",
      "Total training time: 16.48 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 122551.71, NNZs: 200, Bias: -13474.060263, T: 28346138, Avg. loss: 0.298561\n",
      "Total training time: 17.39 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 117327.72, NNZs: 200, Bias: -13300.095214, T: 29838040, Avg. loss: 0.276700\n",
      "Total training time: 18.30 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 112520.68, NNZs: 200, Bias: -13216.884331, T: 31329942, Avg. loss: 0.256382\n",
      "Total training time: 19.22 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 108107.05, NNZs: 200, Bias: -12978.346774, T: 32821844, Avg. loss: 0.239905\n",
      "Total training time: 20.13 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104010.86, NNZs: 200, Bias: -12876.217901, T: 34313746, Avg. loss: 0.224639\n",
      "Total training time: 21.04 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 100211.96, NNZs: 200, Bias: -12777.415927, T: 35805648, Avg. loss: 0.208196\n",
      "Total training time: 21.96 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 96693.65, NNZs: 200, Bias: -12563.837796, T: 37297550, Avg. loss: 0.197785\n",
      "Total training time: 22.87 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 93403.67, NNZs: 200, Bias: -12426.168948, T: 38789452, Avg. loss: 0.188570\n",
      "Total training time: 23.78 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 90327.23, NNZs: 200, Bias: -12314.775785, T: 40281354, Avg. loss: 0.177223\n",
      "Total training time: 24.69 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 87460.13, NNZs: 200, Bias: -12123.633474, T: 41773256, Avg. loss: 0.163982\n",
      "Total training time: 25.61 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 84753.17, NNZs: 200, Bias: -12042.035316, T: 43265158, Avg. loss: 0.159164\n",
      "Total training time: 26.52 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 82207.93, NNZs: 200, Bias: -11960.916845, T: 44757060, Avg. loss: 0.149164\n",
      "Total training time: 27.44 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 79818.73, NNZs: 200, Bias: -11823.510693, T: 46248962, Avg. loss: 0.143237\n",
      "Total training time: 28.35 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 77559.51, NNZs: 200, Bias: -11727.432592, T: 47740864, Avg. loss: 0.134849\n",
      "Total training time: 29.26 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 75434.14, NNZs: 200, Bias: -11560.346671, T: 49232766, Avg. loss: 0.128455\n",
      "Total training time: 30.17 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 73416.31, NNZs: 200, Bias: -11452.113685, T: 50724668, Avg. loss: 0.120598\n",
      "Total training time: 31.08 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 71508.14, NNZs: 200, Bias: -11311.699469, T: 52216570, Avg. loss: 0.116403\n",
      "Total training time: 32.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 69691.69, NNZs: 200, Bias: -11209.752253, T: 53708472, Avg. loss: 0.109291\n",
      "Total training time: 32.91 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 67972.97, NNZs: 200, Bias: -11059.649584, T: 55200374, Avg. loss: 0.105316\n",
      "Total training time: 33.82 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 66331.94, NNZs: 200, Bias: -10946.055516, T: 56692276, Avg. loss: 0.101759\n",
      "Total training time: 34.73 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 64770.11, NNZs: 200, Bias: -10834.851206, T: 58184178, Avg. loss: 0.092870\n",
      "Total training time: 35.64 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 63282.51, NNZs: 200, Bias: -10710.147275, T: 59676080, Avg. loss: 0.091159\n",
      "Total training time: 36.55 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 61861.64, NNZs: 200, Bias: -10589.023281, T: 61167982, Avg. loss: 0.089010\n",
      "Total training time: 37.46 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 60503.49, NNZs: 200, Bias: -10470.958368, T: 62659884, Avg. loss: 0.084785\n",
      "Total training time: 38.37 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 59196.79, NNZs: 200, Bias: -10398.645060, T: 64151786, Avg. loss: 0.082548\n",
      "Total training time: 39.28 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 57956.40, NNZs: 200, Bias: -10271.576445, T: 65643688, Avg. loss: 0.077024\n",
      "Total training time: 40.20 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 56753.87, NNZs: 200, Bias: -10216.800899, T: 67135590, Avg. loss: 0.076745\n",
      "Total training time: 41.10 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 55607.69, NNZs: 200, Bias: -10121.670305, T: 68627492, Avg. loss: 0.071228\n",
      "Total training time: 42.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 54515.21, NNZs: 200, Bias: -9988.440204, T: 70119394, Avg. loss: 0.069684\n",
      "Total training time: 42.93 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 53451.73, NNZs: 200, Bias: -9936.312584, T: 71611296, Avg. loss: 0.066487\n",
      "Total training time: 43.85 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 52439.45, NNZs: 200, Bias: -9821.263838, T: 73103198, Avg. loss: 0.065914\n",
      "Total training time: 44.76 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 51459.14, NNZs: 200, Bias: -9745.957343, T: 74595100, Avg. loss: 0.063194\n",
      "Total training time: 45.67 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 50519.53, NNZs: 200, Bias: -9647.330631, T: 76087002, Avg. loss: 0.059122\n",
      "Total training time: 46.58 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 49616.09, NNZs: 200, Bias: -9538.443213, T: 77578904, Avg. loss: 0.059383\n",
      "Total training time: 47.49 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 48737.02, NNZs: 200, Bias: -9478.829616, T: 79070806, Avg. loss: 0.054911\n",
      "Total training time: 48.40 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 47898.31, NNZs: 200, Bias: -9373.559467, T: 80562708, Avg. loss: 0.052373\n",
      "Total training time: 49.31 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 47083.09, NNZs: 200, Bias: -9293.149693, T: 82054610, Avg. loss: 0.051767\n",
      "Total training time: 50.22 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 46291.46, NNZs: 200, Bias: -9236.781064, T: 83546512, Avg. loss: 0.048736\n",
      "Total training time: 51.13 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 45535.36, NNZs: 200, Bias: -9136.714301, T: 85038414, Avg. loss: 0.047565\n",
      "Total training time: 52.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 44792.56, NNZs: 200, Bias: -9092.971584, T: 86530316, Avg. loss: 0.047956\n",
      "Total training time: 52.95 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 44084.78, NNZs: 200, Bias: -8996.476341, T: 88022218, Avg. loss: 0.046440\n",
      "Total training time: 53.86 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 43390.75, NNZs: 200, Bias: -8943.686730, T: 89514120, Avg. loss: 0.045968\n",
      "Total training time: 54.77 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 42716.39, NNZs: 200, Bias: -8901.948510, T: 91006022, Avg. loss: 0.042099\n",
      "Total training time: 55.68 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 42070.85, NNZs: 200, Bias: -8819.726575, T: 92497924, Avg. loss: 0.043057\n",
      "Total training time: 56.59 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 41436.78, NNZs: 200, Bias: -8779.092371, T: 93989826, Avg. loss: 0.040051\n",
      "Total training time: 57.50 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 40837.89, NNZs: 200, Bias: -8659.655360, T: 95481728, Avg. loss: 0.040538\n",
      "Total training time: 58.42 seconds.\n",
      "-- Epoch 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 40238.53, NNZs: 200, Bias: -8630.256580, T: 96973630, Avg. loss: 0.038898\n",
      "Total training time: 59.33 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 39666.50, NNZs: 200, Bias: -8552.784828, T: 98465532, Avg. loss: 0.038781\n",
      "Total training time: 60.24 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 39105.08, NNZs: 200, Bias: -8505.065505, T: 99957434, Avg. loss: 0.036739\n",
      "Total training time: 61.15 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 38565.09, NNZs: 200, Bias: -8429.725599, T: 101449336, Avg. loss: 0.037597\n",
      "Total training time: 62.06 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 38032.54, NNZs: 200, Bias: -8392.521706, T: 102941238, Avg. loss: 0.035574\n",
      "Total training time: 62.97 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 37522.22, NNZs: 200, Bias: -8319.230738, T: 104433140, Avg. loss: 0.034479\n",
      "Total training time: 63.88 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 37027.74, NNZs: 200, Bias: -8238.243873, T: 105925042, Avg. loss: 0.033899\n",
      "Total training time: 64.79 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 36542.52, NNZs: 200, Bias: -8175.985190, T: 107416944, Avg. loss: 0.033017\n",
      "Total training time: 65.70 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 36068.63, NNZs: 200, Bias: -8123.329649, T: 108908846, Avg. loss: 0.031670\n",
      "Total training time: 66.61 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 35608.82, NNZs: 200, Bias: -8062.721335, T: 110400748, Avg. loss: 0.032218\n",
      "Total training time: 67.52 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 35151.85, NNZs: 200, Bias: -8045.530386, T: 111892650, Avg. loss: 0.029027\n",
      "Total training time: 68.43 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 34717.00, NNZs: 200, Bias: -7977.719410, T: 113384552, Avg. loss: 0.031037\n",
      "Total training time: 69.34 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 34295.09, NNZs: 200, Bias: -7902.424498, T: 114876454, Avg. loss: 0.029558\n",
      "Total training time: 70.25 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 33876.25, NNZs: 200, Bias: -7861.028578, T: 116368356, Avg. loss: 0.029400\n",
      "Total training time: 71.16 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 33464.59, NNZs: 200, Bias: -7836.463064, T: 117860258, Avg. loss: 0.027850\n",
      "Total training time: 72.07 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 33075.95, NNZs: 200, Bias: -7755.972792, T: 119352160, Avg. loss: 0.027954\n",
      "Total training time: 72.98 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 32683.61, NNZs: 200, Bias: -7732.084351, T: 120844062, Avg. loss: 0.026460\n",
      "Total training time: 73.89 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 32309.41, NNZs: 200, Bias: -7669.045006, T: 122335964, Avg. loss: 0.025993\n",
      "Total training time: 74.81 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 31938.37, NNZs: 200, Bias: -7630.103776, T: 123827866, Avg. loss: 0.025867\n",
      "Total training time: 75.72 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 31576.54, NNZs: 200, Bias: -7591.474268, T: 125319768, Avg. loss: 0.023861\n",
      "Total training time: 76.63 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 31224.30, NNZs: 200, Bias: -7545.756269, T: 126811670, Avg. loss: 0.025204\n",
      "Total training time: 77.54 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 30879.67, NNZs: 200, Bias: -7500.759294, T: 128303572, Avg. loss: 0.025923\n",
      "Total training time: 78.45 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 30542.68, NNZs: 200, Bias: -7456.214753, T: 129795474, Avg. loss: 0.024211\n",
      "Total training time: 79.37 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 30213.31, NNZs: 200, Bias: -7412.212093, T: 131287376, Avg. loss: 0.024141\n",
      "Total training time: 80.28 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 29889.56, NNZs: 200, Bias: -7375.807128, T: 132779278, Avg. loss: 0.023260\n",
      "Total training time: 81.19 seconds.\n",
      "Convergence after 89 epochs took 81.19 seconds\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier(loss='hinge', penalty='l2', max_iter=100, alpha=1e-9, tol=1e-3, random_state=123456, class_weight=None, verbose=1)\n",
    "clf.fit(X_train_new, y_train)\n",
    "y_pred_train = clf.predict(X_train_new)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_train)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_svm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "y_pred_test = clf.predict(X_test_new)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " ...\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "ynew = np.array(y_pred_test)\n",
    "ynew = ynew.reshape(-1,2)\n",
    "# display the array\n",
    "print(ynew)\n",
    "  \n",
    "# convert array into dataframe\n",
    "DF = pd.DataFrame(ynew)\n",
    "  \n",
    "# save the dataframe as a csv file\n",
    "DF.to_csv(\"output_svm_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
